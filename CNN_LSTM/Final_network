from pytictoc import TicToc

t = TicToc()

t.tic()

import numpy as np

import matplotlib.pyplot as plt

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Model
from tensorflow.keras.utils import plot_model

train_file_name = 'batch_train_data_final1'
train_label_file_name = 'batch_train_label_data1'

batch_train_data_final = np.load('C:/Users/user/.spyder-py3/CNN_LSTM/data/train/{}.npy'.format(train_file_name))
batch_train_label_data = np.load('C:/Users/user/.spyder-py3/CNN_LSTM/data/train/{}.npy'.format(train_label_file_name))



# batch_train_data_final.reshape(-1, 310, 1000, 1)

### CNN-LSTM ###

map_img_frame_ = (310,1000)

input_data_1 = layers.Input(shape=map_img_frame_, name = 'map_img_')

inner_cnn_rnn_ = layers.LSTM(64, return_sequences = True, name='lstm1')(input_data_1)
inner_cnn_rnn_ = layers.Bidirectional(layers.LSTM(64, return_sequences=True), name='lstm2')(inner_cnn_rnn_)
inner_cnn_rnn_ = layers.Dense(1000, activation='relu', kernel_initializer='he_normal', name='dense1')(inner_cnn_rnn_)

# inner_cnn_rnn_ = layers.Conv2D(2,(3, 3), padding = 'same', name = 'conv1')(input_data_1)
# inner_cnn_rnn_ = layers.Activation('relu', name = 'act1')(inner_cnn_rnn_)
# inner_cnn_rnn_ = layers.MaxPooling2D(pool_size=(2,2), strides=(1, 1), padding ='same', name='max1')(inner_cnn_rnn_)

# inner_cnn_rnn_ = layers.Conv2D(1,(3, 3), padding = 'same', name = 'conv2')(inner_cnn_rnn_)
# inner_cnn_rnn_ = layers.Activation('relu', name = 'act2')(inner_cnn_rnn_)
# inner_cnn_rnn_ = layers.MaxPooling2D(pool_size=(2,2), strides=(1, 1), padding ='same', name='max2')(inner_cnn_rnn_)

# inner_cnn_rnn_ = layers.Reshape(target_shape=((1000,310)), name='reshape1')(inner_cnn_rnn_)

# inner_cnn_rnn_ = layers.LSTM(64, return_sequences = True, name='lstm1')(inner_cnn_rnn_)
# inner_cnn_rnn_ = layers.Bidirectional(layers.LSTM(64, return_sequences=True), name='lstm2')(inner_cnn_rnn_)

# inner_cnn_rnn_ = layers.Dense(310, activation='relu', kernel_initializer='he_normal', name='dense1')(inner_cnn_rnn_)
# inner_cnn_rnn_ = layers.Reshape(target_shape=((310, 1000)), name='reshape2')(inner_cnn_rnn_)

modelfinal = Model(inputs=input_data_1, outputs=inner_cnn_rnn_)

modelfinal.compile(
    loss=keras.losses.MeanSquaredError(),
    optimizer=keras.optimizers.Adam(),
    metrics=['accuracy'],
)

num = len(batch_train_data_final)
epoch = 1000
batch_size = 4
st = '(1)'

checkpoint_path = './CNN_LSTM/Model/Final/best/save/%d_EP%d_BS%d%s_best_{epoch:02d}-{loss:.5f}.h5'%(num, epoch, batch_size, st)

early_stopping = keras.callbacks.EarlyStopping(monitor="loss", patience=30)

mc = keras.callbacks.ModelCheckpoint(
    filepath = checkpoint_path,
    monitor='loss',
    save_best_only=True
)

history = modelfinal.fit(
    batch_train_data_final,
    batch_train_label_data,
    batch_size=batch_size,
    epochs=epoch,
    validation_split=0.3,
    # callbacks=[early_stopping],
    # callbacks=[early_stopping, mc],
    # callbacks=[early_stopping, reduce_lr],
    callbacks=[mc],
)

plt.figure(figsize=(15, 10))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], 'b--', label='loss')
plt.plot(history.history['val_loss'], 'r:', label='val loss')
plt.xlabel('Epochs')
plt.grid()
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], 'b--', label='accuracy')
plt.plot(history.history['val_accuracy'], 'r:', label='val accuracy')
plt.xlabel('Epochs')
plt.grid()
plt.legend()

modelfinal.summary()
# modelfinal.evaluate(CL_test, CL_test_label)

modelfinal.save('./CNN_LSTM/Model/Final/CNN_LSTM_model_%d_EP%d_BS%d%s.h5'%(num, epoch, batch_size, st))
plot_model(modelfinal, to_file='./CNN_LSTM/Model/Final/model_plot/plot_%d_EP%d_BS%d%s.h5.png'%(num, epoch, batch_size, st), show_shapes=True)
plt.savefig('./CNN_LSTM/Model/Final/loss_plot/%d_%d_%d%s.h5.png'%(num, epoch, batch_size, st), dpi=300)

t.toc()

